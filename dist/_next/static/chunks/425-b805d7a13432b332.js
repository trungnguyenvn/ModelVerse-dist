"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[425],{70607:(e,t,a)=>{a.d(t,{g:()=>y});var s=a(95155),i=a(12115),n=a(5034),r=a(69920),o=a(28918),l=a(75334),d=a(93934),m=a(87465),u=a(69635);let c={showAllModels:!1,selectedCategory:u.hM.All,selectedProvider:"all",selectedTier:"all"},g=e=>{let[t,a]=(0,i.useState)(c);(0,i.useEffect)(()=>{e&&s()},[e]);let s=async()=>{try{let e=await n.Z.getFormState();e&&a(e)}catch(e){console.error("Error loading form state:",e)}},r=async e=>{try{await n.Z.saveFormState(e),a(e)}catch(e){console.error("Error saving form state:",e)}},o=async e=>{let a={...t,showAllModels:e};await r(a)},l=async e=>{let a={...t,selectedCategory:e};await r(a)},d=async e=>{let a={...t,selectedProvider:e};await r(a)},m=async e=>{let a={...t,selectedTier:e};await r(a)};return{state:t,updateShowAllModels:o,updateCategory:l,updateProvider:d,updateTier:m}};var p=a(38962);let h=e=>{var t;let{options:a,selected:n,onChange:r,label:o}=e,[l,d]=(0,i.useState)(!1),u=(0,i.useRef)(null);return(0,i.useEffect)(()=>{let e=e=>{u.current&&!u.current.contains(e.target)&&d(!1)};return document.addEventListener("mousedown",e),()=>document.removeEventListener("mousedown",e)},[]),(0,s.jsxs)("div",{className:"relative min-w-[150px]",ref:u,children:[(0,s.jsxs)("button",{type:"button",onClick:()=>d(!l),className:"flex w-full items-center justify-between rounded-md border border-gray-300 px-3 py-2 text-sm text-gray-700 hover:bg-gray-50 dark:border-gray-600 dark:text-gray-300 dark:hover:bg-gray-800","aria-expanded":l,"aria-haspopup":"listbox",children:[(0,s.jsx)("span",{children:(null===(t=a.find(e=>e.id===n))||void 0===t?void 0:t.name)||o}),(0,s.jsx)(m.A,{className:"ml-2 h-4 w-4 transition-transform ".concat(l?"rotate-180":""),"aria-hidden":"true"})]}),l&&(0,s.jsx)("ul",{className:"absolute z-10 mt-1 max-h-60 w-full overflow-auto rounded-md bg-white py-1 shadow-lg ring-1 ring-black ring-opacity-5 dark:bg-gray-800",children:a.map(e=>(0,s.jsx)("li",{onClick:()=>{r(e.id),d(!1)},className:"cursor-pointer px-3 py-2 text-sm hover:bg-gray-100 dark:hover:bg-gray-700\n                ".concat(n===e.id?"bg-blue-50 text-blue-600 dark:bg-blue-900/50 dark:text-blue-400":"text-gray-700 dark:text-gray-300"),role:"option","aria-selected":n===e.id,children:e.name},e.id))})]})},x=e=>{let{selectedModel:t,onModelSelect:a,isOpen:n}=e,{availableModels:r}=(0,p.$)(),{state:o,updateShowAllModels:l,updateCategory:d,updateProvider:m,updateTier:c}=g(n),{showAllModels:x,selectedCategory:v,selectedProvider:b,selectedTier:f}=o,y=(0,i.useMemo)(()=>(null==r?void 0:r.length)?u.L6.filter(e=>r.some(t=>t.modelId===e.id.replace("us.",""))):u.L6,[r]),w=[{id:u.hM.All,name:"All Models"},{id:u.hM.Chat,name:"Chat"},{id:u.hM.Image,name:"Image"},{id:u.hM.Multimodal,name:"Multimodal"}],T=(0,i.useMemo)(()=>{let e=new Set;return y.forEach(t=>e.add(t.provider)),["all",...Array.from(e)].map(e=>({id:e,name:"all"===e?"All Providers":e}))},[y]),C=(0,i.useMemo)(()=>y.filter(e=>{let t=v===u.hM.All||e.category.includes(v),a="all"===b||e.provider===b,s="all"===f||e.tier===f;return t&&a&&s}),[v,b,f,y]),[M,S]=(0,i.useState)(!0);if((0,i.useEffect)(()=>{void 0!==r&&S(!1)},[r]),M)return(0,s.jsx)("div",{className:"bg-white rounded-lg shadow p-4",children:(0,s.jsx)("div",{className:"animate-pulse flex space-x-4",children:(0,s.jsxs)("div",{className:"flex-1 space-y-4 py-1",children:[(0,s.jsx)("div",{className:"h-4 bg-gray-200 rounded w-3/4"}),(0,s.jsxs)("div",{className:"space-y-2",children:[(0,s.jsx)("div",{className:"h-4 bg-gray-200 rounded"}),(0,s.jsx)("div",{className:"h-4 bg-gray-200 rounded w-5/6"})]})]})})});if(0===y.length)return(0,s.jsx)("div",{className:"bg-white rounded-lg shadow p-4",children:(0,s.jsx)("div",{className:"text-center text-gray-500",children:"No models available in this region. Please try another region."})});let k=e=>(0,s.jsx)("div",{className:"group",children:(0,s.jsx)("button",{type:"button",onClick:()=>a(e.id),className:"\n              w-full text-left rounded-lg border transition-colors\n              ".concat(t===e.id?"border-blue-500 bg-blue-50 dark:border-blue-400 dark:bg-blue-900/20":"border-gray-200 group-hover:bg-gray-50 dark:border-gray-700 dark:group-hover:bg-gray-800","\n            "),children:(0,s.jsx)("div",{className:"p-3",children:(0,s.jsxs)("div",{className:"flex flex-col min-w-0",children:[(0,s.jsx)("span",{className:"font-medium text-gray-900 dark:text-gray-100 truncate",children:e.name}),(0,s.jsxs)("div",{className:"flex items-center space-x-2 text-sm text-gray-500 dark:text-gray-400",children:[(0,s.jsx)("span",{className:"truncate",children:e.provider}),(0,s.jsx)("span",{children:"•"}),(0,s.jsx)("span",{className:"capitalize",children:e.tier})]}),t===e.id&&(0,s.jsxs)("div",{className:"flex flex-wrap gap-1 mt-2",children:[e.capabilities.map((e,t)=>(0,s.jsx)("span",{className:"\n                          px-2 py-1 text-xs rounded-full whitespace-nowrap\n                          ".concat("chat"===e?"bg-green-100 text-green-800 dark:bg-green-900/50 dark:text-green-300":"text generation"===e?"bg-blue-100 text-blue-800 dark:bg-blue-900/50 dark:text-blue-300":"image generation"===e?"bg-purple-100 text-purple-800 dark:bg-purple-900/50 dark:text-purple-300":"bg-gray-100 text-gray-800 dark:bg-gray-800 dark:text-gray-300","\n                        "),children:e},t)),e.streaming&&(0,s.jsx)("span",{className:"px-2 py-1 text-xs bg-gray-100 text-gray-800 dark:bg-gray-800 dark:text-gray-300 rounded-full whitespace-nowrap",children:"Streaming supported"})]})]})})})},e.id);return(0,s.jsxs)("div",{className:"bg-white dark:bg-gray-900 rounded-lg shadow flex flex-col h-[calc(100vh-200px)] max-h-[400px] min-w-[300px] lg:min-w-[500px]",children:[(0,s.jsxs)("div",{className:"flex flex-col border-b dark:border-gray-800 bg-white dark:bg-gray-900 sticky top-0 z-10",children:[(0,s.jsxs)("div",{className:"flex items-center gap-x-4 p-4 dark:border-gray-800",children:[(0,s.jsx)(h,{options:w,selected:v,onChange:d,label:"Category"}),(0,s.jsx)(h,{options:T,selected:b,onChange:m,label:"Provider"})]}),(0,s.jsx)("div",{className:"flex items-center gap-x-4 p-4 border-b dark:border-gray-800",children:(0,s.jsx)(h,{options:[{id:"all",name:"All Tiers"},{id:"basic",name:"Basic"},{id:"standard",name:"Standard"},{id:"premium",name:"Premium"}],selected:f,onChange:c,label:"Tier"})})]}),(0,s.jsx)("div",{className:"flex-1 overflow-y-auto overflow-x-hidden",children:(0,s.jsx)("div",{className:"p-4",children:(0,s.jsx)("div",{className:"space-y-2",children:C.map(e=>k(e))})})})]})};var v=a(14778),b=a(20984);let f=e=>{let{isOpen:t,onClose:a,onSave:n,initialAgent:o}=e,[l,d]=(0,i.useState)(()=>o?{...o}:{id:crypto.randomUUID(),name:"",description:"",systemPrompt:"",modelParams:{modelId:"",temperature:.7,topP:1,maxTokens:1024,maxTurns:10},createdAt:Date.now(),updatedAt:Date.now()}),m=(0,v.UT)(l.modelParams.modelId),c=null==m?void 0:m.category.includes(u.hM.Image);return((0,i.useEffect)(()=>{o&&d({...o})},[o]),t)?(0,s.jsx)("div",{className:"fixed inset-0 z-[60] overflow-y-auto",children:(0,s.jsx)("div",{className:"flex items-center justify-center min-h-screen p-4",children:(0,s.jsxs)("div",{className:"relative bg-white rounded-lg w-full max-w-2xl p-6",children:[(0,s.jsxs)("div",{className:"flex justify-between items-center mb-4",children:[(0,s.jsx)("h3",{className:"text-lg font-medium",children:o?"Edit Agent":"Create New Agent"}),(0,s.jsx)("button",{onClick:a,children:(0,s.jsx)(r.A,{size:20})})]}),(0,s.jsxs)("form",{onSubmit:e=>{e.preventDefault(),n({...l,updatedAt:Date.now()})},className:"space-y-4",children:[(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Agent Name"}),(0,s.jsx)("input",{type:"text",value:l.name,onChange:e=>d({...l,name:e.target.value}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500",required:!0})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Description"}),(0,s.jsx)("input",{type:"text",value:l.description,onChange:e=>d({...l,description:e.target.value}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500",required:!0})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"System Prompt"}),(0,s.jsx)("textarea",{value:l.systemPrompt,onChange:e=>d({...l,systemPrompt:e.target.value}),rows:4,className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500",required:!0})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700 mb-2",children:"Model"}),(0,s.jsx)(x,{selectedModel:l.modelParams.modelId,onModelSelect:e=>d({...l,modelParams:{...l.modelParams,modelId:e}}),isOpen:!0})]}),(0,s.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-4",children:c?(()=>{var e;return(0,s.jsx)(s.Fragment,{children:(null==m?void 0:m.provider)===u.cp.Amazon?(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Task Type"}),(0,s.jsxs)("select",{value:l.modelParams.taskType||"TEXT_IMAGE",onChange:e=>d({...l,modelParams:{...l.modelParams,taskType:e.target.value}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500",children:[(0,s.jsx)("option",{value:"TEXT_IMAGE",children:"Text to Image"}),(0,s.jsx)("option",{value:"INPAINTING",children:"Inpainting"}),(0,s.jsx)("option",{value:"OUTPAINTING",children:"Outpainting"}),(0,s.jsx)("option",{value:"IMAGE_VARIATION",children:"Image Variation"}),m.id.includes("v2")&&(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)("option",{value:"COLOR_GUIDED_GENERATION",children:"Color Guided"}),(0,s.jsx)("option",{value:"BACKGROUND_REMOVAL",children:"Background Removal"})]})]})]}),(0,s.jsxs)("div",{className:"grid grid-cols-2 gap-2",children:[(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Width"}),(0,s.jsx)("input",{type:"number",min:512,max:1024,step:8,value:l.modelParams.imageWidth||1024,onChange:e=>d({...l,modelParams:{...l.modelParams,imageWidth:parseInt(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Height"}),(0,s.jsx)("input",{type:"number",min:512,max:1024,step:8,value:l.modelParams.imageHeight||1024,onChange:e=>d({...l,modelParams:{...l.modelParams,imageHeight:parseInt(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Number of Images"}),(0,s.jsx)("input",{type:"number",min:1,max:4,value:l.modelParams.numImages||1,onChange:e=>d({...l,modelParams:{...l.modelParams,numImages:parseInt(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"CFG Scale"}),(0,s.jsx)("input",{type:"number",min:1,max:20,step:.5,value:l.modelParams.cfgScale||7.5,onChange:e=>d({...l,modelParams:{...l.modelParams,cfgScale:parseFloat(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Negative Prompt"}),(0,s.jsx)("textarea",{value:l.modelParams.negativeText,onChange:e=>d({...l,modelParams:{...l.modelParams,negativeText:e.target.value}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500",rows:2,placeholder:"What to avoid in the image (minimum 3 characters)..."})]}),"TEXT_IMAGE"===l.modelParams.taskType&&m.id.includes("v2")&&(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Control Mode"}),(0,s.jsxs)("select",{value:l.modelParams.controlMode||"CANNY_EDGE",onChange:e=>d({...l,modelParams:{...l.modelParams,controlMode:e.target.value}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500",children:[(0,s.jsx)("option",{value:"CANNY_EDGE",children:"Canny Edge"}),(0,s.jsx)("option",{value:"SEGMENTATION",children:"Segmentation"})]})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Control Strength"}),(0,s.jsx)("input",{type:"number",min:0,max:1,step:.1,value:l.modelParams.controlStrength||.7,onChange:e=>d({...l,modelParams:{...l.modelParams,controlStrength:parseFloat(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]})]}),"COLOR_GUIDED_GENERATION"===l.modelParams.taskType&&(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Color Hex Codes"}),(0,s.jsx)("input",{type:"text",value:(null===(e=l.modelParams.colors)||void 0===e?void 0:e.join(", "))||"",onChange:e=>d({...l,modelParams:{...l.modelParams,colors:e.target.value.split(",").map(e=>e.trim())}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500",placeholder:"#FF0000, #00FF00, #0000FF"})]}),("INPAINTING"===l.modelParams.taskType||"OUTPAINTING"===l.modelParams.taskType)&&(0,s.jsx)(s.Fragment,{children:(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Mask Prompt"}),(0,s.jsx)("input",{type:"text",value:l.modelParams.maskPrompt||"",onChange:e=>d({...l,modelParams:{...l.modelParams,maskPrompt:e.target.value}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500",placeholder:"Describe the area to mask..."})]})}),"IMAGE_VARIATION"===l.modelParams.taskType&&(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Similarity Strength"}),(0,s.jsx)("input",{type:"number",min:.2,max:1,step:.1,value:l.modelParams.similarityStrength||.7,onChange:e=>d({...l,modelParams:{...l.modelParams,similarityStrength:parseFloat(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]})]}):(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-xs font-medium text-gray-700 mb-1",children:"Aspect Ratio"}),(0,s.jsx)("select",{value:l.modelParams.aspectRatio,onChange:e=>d({...l,modelParams:{...l.modelParams,aspectRatio:e.target.value}}),className:"w-full px-2 py-1 text-sm border rounded focus:outline-none focus:ring-1 focus:ring-blue-500",children:b.iB.map(e=>(0,s.jsx)("option",{value:e,children:e},e))})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-xs font-medium text-gray-700 mb-1",children:"Output Format"}),(0,s.jsx)("select",{value:l.modelParams.outputFormat,onChange:e=>d({...l,modelParams:{...l.modelParams,outputFormat:e.target.value}}),className:"w-full px-2 py-1 text-sm border rounded focus:outline-none focus:ring-1 focus:ring-blue-500",children:b.zQ.map(e=>(0,s.jsx)("option",{value:e,children:e.toUpperCase()},e))})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-xs font-medium text-gray-700 mb-1",children:"Negative Prompt"}),(0,s.jsx)("textarea",{value:l.modelParams.negativePrompt,onChange:e=>d({...l,modelParams:{...l.modelParams,negativePrompt:e.target.value}}),className:"w-full px-2 py-1 text-sm border rounded focus:outline-none focus:ring-1 focus:ring-blue-500 resize-y",placeholder:"What to avoid in the image...",rows:2})]}),"image-to-image"===l.modelParams.mode&&(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-xs font-medium text-gray-700 mb-1",children:"Strength"}),(0,s.jsxs)("div",{className:"flex items-center space-x-2",children:[(0,s.jsx)("input",{type:"range",min:0,max:1,step:"0.1",value:l.modelParams.strength,onChange:e=>d({...l,modelParams:{...l.modelParams,strength:parseFloat(e.target.value)}}),className:"flex-1"}),(0,s.jsx)("span",{className:"text-xs text-gray-500 w-12 text-right",children:l.modelParams.strength})]})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-xs font-medium text-gray-700 mb-1",children:"Seed"}),(0,s.jsx)("input",{type:"number",value:l.modelParams.seed,onChange:e=>d({...l,modelParams:{...l.modelParams,seed:parseInt(e.target.value)}}),className:"w-full px-2 py-1 text-sm border rounded focus:outline-none focus:ring-1 focus:ring-blue-500"})]})]})})})():(0,s.jsxs)(s.Fragment,{children:[(null==m?void 0:m.parameters.supportsTemperature)&&(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Temperature"}),(0,s.jsx)("input",{type:"number",min:0,max:1,step:.1,value:l.modelParams.temperature,onChange:e=>d({...l,modelParams:{...l.modelParams,temperature:parseFloat(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Max Tokens"}),(0,s.jsx)("input",{type:"number",min:1,max:(null==m?void 0:m.maxOutputTokens)||4096,value:l.modelParams.maxTokens,onChange:e=>d({...l,modelParams:{...l.modelParams,maxTokens:parseInt(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]}),(null==m?void 0:m.parameters.supportsTopP)&&(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Top P"}),(0,s.jsx)("input",{type:"number",min:0,max:1,step:.1,value:l.modelParams.topP,onChange:e=>d({...l,modelParams:{...l.modelParams,topP:parseFloat(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]}),(null==m?void 0:m.parameters.supportsTopK)&&(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Top K"}),(0,s.jsx)("input",{type:"number",min:0,max:250,value:l.modelParams.topK||"",onChange:e=>d({...l,modelParams:{...l.modelParams,topK:e.target.value?parseInt(e.target.value):void 0}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("label",{className:"block text-sm font-medium text-gray-700",children:"Turn rounds"}),(0,s.jsx)("input",{type:"number",min:1,max:25,value:l.modelParams.maxTurns,onChange:e=>d({...l,modelParams:{...l.modelParams,maxTurns:parseInt(e.target.value)}}),className:"mt-1 p-2 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"})]})]})}),(0,s.jsxs)("div",{className:"flex justify-end space-x-3 mt-6",children:[(0,s.jsx)("button",{type:"button",onClick:a,className:"px-4 py-2 text-sm font-medium text-gray-700 bg-white border border-gray-300 rounded-md hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500",children:"Cancel"}),(0,s.jsx)("button",{type:"submit",className:"px-4 py-2 text-sm font-medium text-white bg-blue-600 border border-transparent rounded-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500",children:o?"Update Agent":"Create Agent"})]})]})]})})}):null},y=e=>{let{isOpen:t,onClose:a}=e,[m,u]=(0,i.useState)([]),[c,g]=(0,i.useState)(!1),[p,h]=(0,i.useState)(null);(0,i.useEffect)(()=>{x()},[]);let x=async()=>{u((await n.Z.getAllAgents()).sort((e,t)=>t.updatedAt-e.updatedAt))},v=async e=>{await n.Z.saveAgent(e),await x(),g(!1),h(null)},b=async e=>{confirm("Are you sure you want to delete this agent?")&&(await n.Z.deleteAgent(e),await x())};return t?(0,s.jsxs)("div",{className:"fixed inset-0 z-50 overflow-y-auto",children:[(0,s.jsxs)("div",{className:"flex items-center justify-center min-h-screen p-4",children:[(0,s.jsx)("div",{className:"fixed inset-0 bg-black bg-opacity-50",onClick:a}),(0,s.jsxs)("div",{className:"relative bg-white rounded-lg w-full max-w-2xl p-6",children:[(0,s.jsxs)("div",{className:"flex justify-between items-center mb-4",children:[(0,s.jsx)("h3",{className:"text-lg font-medium",children:"Agent Manager"}),(0,s.jsx)("button",{onClick:a,children:(0,s.jsx)(r.A,{size:20})})]}),(0,s.jsxs)("div",{className:"mt-4 space-y-4",children:[m.map(e=>(0,s.jsxs)("div",{className:"flex items-center justify-between p-4 border rounded-lg",children:[(0,s.jsxs)("div",{children:[(0,s.jsx)("h4",{className:"font-medium",children:e.name}),(0,s.jsx)("p",{className:"text-sm text-gray-500 truncate max-w-md",children:e.description})]}),(0,s.jsxs)("div",{className:"flex space-x-2",children:[(0,s.jsx)("button",{onClick:()=>{h(e),g(!0)},className:"p-2 text-gray-600 hover:bg-gray-100 rounded",children:(0,s.jsx)(o.A,{size:20})}),(0,s.jsx)("button",{onClick:()=>b(e.id),className:"p-2 text-red-600 hover:bg-red-50 rounded",children:(0,s.jsx)(l.A,{size:20})})]})]},e.id)),(0,s.jsxs)("button",{onClick:()=>{h(null),g(!0)},className:"w-full py-3 flex items-center justify-center space-x-2  text-blue-600 border-2 border-dashed border-blue-300  rounded-lg hover:bg-blue-50",children:[(0,s.jsx)(d.A,{size:20}),(0,s.jsx)("span",{children:"Add New Agent"})]})]})]})]}),c&&(0,s.jsx)(f,{isOpen:c,onClose:()=>g(!1),onSave:v,initialAgent:p})]}):null}},3031:(e,t,a)=>{a.d(t,{j:()=>l,g:()=>d});var s=a(95155),i=a(12115),n=a(5034),r=a(79749);let o=(0,i.createContext)(void 0);function l(e){let{children:t}=e,a=function(){let[e,t]=(0,i.useState)([]),[a,s]=(0,i.useState)(null),[o,l]=(0,i.useState)(!0),[d,m]=(0,i.useState)(null);(0,i.useEffect)(()=>{u()},[]),(0,i.useEffect)(()=>{let e=sessionStorage.getItem("currentConversationId");e&&c(e)},[]);let u=async()=>{try{l(!0);let e=(await n.Z.initDB()).transaction("conversations","readonly").objectStore("conversations").getAll();e.onsuccess=()=>{let a=e.result.sort((e,t)=>t.lastEditedAt-e.lastEditedAt);t(a),l(!1)},e.onerror=()=>{throw Error("Failed to load conversations")}}catch(e){m(e instanceof Error?e:Error("Unknown error")),l(!1)}},c=async e=>{try{let t=await n.Z.getConversation(e);t&&(s(t),sessionStorage.setItem("currentConversationId",e))}catch(e){m(e instanceof Error?e:Error("Failed to set active conversation"))}},g=async e=>{if(a)try{await n.Z.updateConversation(a.id,e);let t=await n.Z.getConversation(a.id);t&&s(t),await u()}catch(e){m(e instanceof Error?e:Error("Failed to update conversation"))}},p=async e=>{if(a)try{await g({messages:e,lastEditedAt:Date.now()})}catch(e){m(e instanceof Error?e:Error("Failed to update messages"))}},h=async e=>{try{let t=(await n.Z.initDB()).transaction("conversations","readwrite").objectStore("conversations");await t.delete(e),(null==a?void 0:a.id)===e&&(s(null),sessionStorage.removeItem("currentConversationId")),await u()}catch(e){m(e instanceof Error?e:Error("Failed to delete conversation"))}},x=async(e,t)=>{try{if(await n.Z.getConversation(e)&&(await n.Z.updateConversation(e,{title:t,lastEditedAt:Date.now()}),await u(),(null==a?void 0:a.id)===e)){let t=await n.Z.getConversation(e);t&&s(t)}}catch(e){m(e instanceof Error?e:Error("Failed to update title"))}};return{conversations:e,activeConversation:a,isLoading:o,error:d,createNewConversation:async()=>{try{let e={id:(0,r.A)(),title:"New Chat",messages:[],createdAt:Date.now(),lastEditedAt:Date.now()};await n.Z.saveConversation(e),await u(),await c(e.id)}catch(e){m(e instanceof Error?e:Error("Failed to create conversation"))}},setActiveConversation:c,updateActiveConversation:g,updateMessages:p,deleteConversation:h,updateConversationTitle:x}}();return(0,s.jsx)(o.Provider,{value:a,children:t})}let d=()=>{let e=(0,i.useContext)(o);if(void 0===e)throw Error("useConversationContext must be used within a ConversationProvider");return e}},38962:(e,t,a)=>{a.d(t,{u:()=>d,$:()=>m});var s=a(95155),i=a(12115),n=a(5034),r=a(95470),o=a(9491);let l=(0,i.createContext)({});function d(e){let{children:t}=e,a=function(){let[e,t]=(0,i.useState)(null),[a,s]=(0,i.useState)([]),[l,d]=(0,i.useState)(!0),m=async e=>{try{d(!0);let t=new r.e({credentials:{accessKeyId:e.accessKeyId,secretAccessKey:e.secretAccessKey},region:e.region}),a=new o.L({}),i=await t.send(a);i.modelSummaries&&(await n.Z.saveAvailableModels({models:i.modelSummaries,region:e.region}),s(i.modelSummaries))}catch(e){console.error("Error fetching available models:",e)}finally{d(!1)}};(0,i.useEffect)(()=>{(async()=>{d(!0);try{let e=await n.Z.getCredentials();if(e){t(e);let a=await n.Z.getAvailableModels(e.region);a?s(a.models):await m(e)}}catch(e){console.error("Error loading credentials:",e)}finally{d(!1)}})()},[]);let u=async a=>{if(e){d(!0);try{let s={...e,region:a};await n.Z.saveCredentials(s),t(s),await m(s)}finally{d(!1)}}};return{credentials:e,availableModels:a,login:async e=>{d(!0);try{await n.Z.saveCredentials(e),t(e),await m(e)}finally{d(!1)}},signOut:async()=>{d(!0);try{await n.Z.deleteCredentials(),t(null),s([])}finally{d(!1)}},switchRegion:u,isLoading:l}}();return(0,s.jsx)(l.Provider,{value:a,children:t})}let m=()=>(0,i.useContext)(l)},20984:(e,t,a)=>{a.d(t,{BZ:()=>n,iB:()=>s,zQ:()=>i});let s=["1:1","16:9","4:3","3:2","2:1"],i=["png","jpeg"],n=["512x512","768x768","1024x1024","768x1152","384x576","1152x768","576x384","768x1280","384x640","1280x768","640x384","896x1152","448x576","1152x896","576x448","768x1408","384x704","1408x768","704x384","640x1408","320x704","1408x640","704x320","1152x640","1173x640"]},69635:(e,t,a)=>{a.d(t,{hM:()=>c,L6:()=>p,cp:()=>u,Z4:()=>g});class s{static getInstance(){return this.instance||(this.instance=new s),this.instance}register(e){!function(e){var t,a;for(let t of["id","name","provider","category","tier","description","capabilities","parameters"])if(!e[t])throw Error("Missing required field: ".concat(t));if(!(null===(t=e.inputModalities)||void 0===t?void 0:t.length)||!(null===(a=e.outputModalities)||void 0===a?void 0:a.length))throw Error("Model must specify input and output modalities")}(e),this.models.set(e.id,e)}getModel(e){return this.models.get(e)}getModels(){return Array.from(this.models.values())}filterModels(e){return this.getModels().filter(e)}getModelsByProvider(e){return this.filterModels(t=>t.provider===e)}getModelsByCategory(e){return this.filterModels(t=>t.category.includes(e))}constructor(){this.models=new Map}}let i={TEXT:{temperature:.7,topP:.9},IMAGE:{quality:"standard",size:"1024x1024"}};class n{getCommonTextModelParams(e){return{supportsTemperature:!0,supportsTopP:!0,defaultValues:{...i.TEXT,maxTokens:e},limits:{minTemperature:0,maxTemperature:1,minTopP:0,maxTopP:1,minTokens:1,maxTokens:e}}}getCommonImageModelParams(){return{supportsTemperature:!1,supportsTopP:!1,defaultValues:i.IMAGE,limits:{minTokens:1,maxTokens:77}}}constructor(){this.registry=s.getInstance()}}class r extends n{generateModels(){this.registry.register({id:"anthropic.claude-3-5-haiku-20241022-v1:0",name:"Claude 3.5 Haiku",provider:u.Anthropic,version:"1.0",category:[c.Agents,c.Chat,c.CodeGeneration,c.ComplexReasoningAnalysis,c.Conversation,c.Math,c.MultilingualSupport,c.QuestionAnswering,c.RAG,c.TextGeneration,c.TextSummarization,c.TextToText,c.Translation],tier:g.Premium,description:"Anthropic's fastest, most compact model for near-instant responsiveness",longDescription:"Claude 3 Haiku is Anthropic's fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with speed. Customers will be able to build seamless AI experiences that mimic human interactions.",capabilities:["Fast response times","Image processing","Text generation","Multilingual support"],inputModalities:["text","image"],outputModalities:["text","chat"],maxInputTokens:2e5,streaming:!0,regions:["us-east-1","us-west-2"],parameters:this.getCommonTextModelParams(2e5),features:{contextWindow:2e5,multilingual:!0,formatting:!0,imageAnalysis:!0,streamingSupport:!0,supportedLanguages:["English","Spanish","Japanese"]},useCase:{recommended:["Quick responses","Simple queries","Seamless AI interactions","Image analysis"],notRecommended:[]},status:"stable",lastUpdated:"2024-10-22"}),this.registry.register({id:"anthropic.claude-3-5-sonnet-20241022-v2:0",name:"Claude 3.5 Sonnet v2",provider:u.Anthropic,version:"v2",category:[c.Agents,c.CodeGeneration,c.ComplexReasoningAnalysis,c.Conversation,c.ImageToText,c.Math,c.MultilingualSupport,c.NaturalLanguageProcessing,c.QuestionAnswering,c.RAG,c.TextGeneration,c.TextSummarization,c.TextToText,c.Translation],tier:g.Premium,description:"The upgraded Claude 3.5 Sonnet is now state-of-the-art for a variety of tasks including real-world software engineering, agentic capabilities and computer use.",capabilities:["Software engineering","Agentic capabilities","Computer use","Multilingual support"],inputModalities:["text","image"],outputModalities:["text","chat"],maxInputTokens:2e5,maxOutputTokens:4096,streaming:!0,regions:["us-east-1","us-west-2"],parameters:this.getCommonTextModelParams(2e5),features:{contextWindow:2e5,multilingual:!0,formatting:!0,imageAnalysis:!0,streamingSupport:!0,supportedLanguages:["English","Spanish","Japanese"]},useCase:{recommended:["Software engineering","Complex reasoning","Multi-modal tasks","Multilingual applications"],notRecommended:[]},status:"stable",lastUpdated:"2024-10-22"}),this.registry.register({id:"anthropic.claude-3-5-sonnet-20240620-v1:0",name:"Claude 3.5 Sonnet",provider:u.Anthropic,version:"v1",category:[c.Agents,c.Chat,c.CodeGeneration,c.ComplexReasoningAnalysis,c.Conversation,c.ImageToText,c.Math,c.MultilingualSupport,c.NaturalLanguageProcessing,c.QuestionAnswering,c.RAG,c.TextGeneration,c.TextSummarization,c.TextToText,c.Translation],tier:g.Standard,description:"Claude 3.5 Sonnet raises the industry bar for intelligence, outperforming competitor models and Claude 3 Opus on a wide range of evaluations, with the speed and cost of our mid-tier model.",capabilities:["Advanced intelligence and reasoning","High performance across evaluations","Optimized speed and cost efficiency","Image analysis","Multilingual support"],inputModalities:["text","image"],outputModalities:["text","chat"],maxInputTokens:2e5,streaming:!0,regions:["us-east-1","us-east-2","us-west-2","us-gov-east-1","us-gov-west-1","ap-northeast-1","ap-northeast-2","ap-south-1","ap-southeast-2","eu-central-1","eu-central-2","eu-west-1","eu-west-3"],parameters:this.getCommonTextModelParams(2e5),features:{contextWindow:2e5,multilingual:!0,formatting:!0,imageAnalysis:!0,streamingSupport:!0,supportedLanguages:["English","Spanish","Japanese","Multiple other languages"]},useCase:{recommended:["Complex reasoning tasks","Code generation","Mathematical problems","Multilingual applications","Image analysis","Text processing and generation"],notRecommended:[]},status:"stable",lastUpdated:"2024-06-20"}),this.registry.register({id:"anthropic.claude-3-opus-20240229-v1:0",name:"Claude 3 Opus",provider:u.Anthropic,version:"v1",category:[c.ImageToText,c.Conversation,c.ComplexReasoningAnalysis,c.MultilingualSupport],tier:g.Premium,description:"Claude 3 Opus is Anthropic's most powerful AI model, with state-of-the-art performance on highly complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding. Claude 3 Opus shows us the frontier of what's possible with generative AI.",capabilities:["State-of-the-art performance on complex tasks","Open-ended prompt handling","Image processing","Multilingual support","Large context window"],inputModalities:["text","image"],outputModalities:["text","chat"],maxInputTokens:2e5,maxOutputTokens:2e5,streaming:!0,regions:["us-east-1","us-west-2"],parameters:this.getCommonTextModelParams(2e5),features:{contextWindow:2e5,multilingual:!0,formatting:!0,imageAnalysis:!0,multimodal:!0,streamingSupport:!0},useCase:{recommended:["Complex reasoning","Image analysis","Multilingual tasks","Long-form content generation","Advanced analysis"],notRecommended:["Simple tasks","Cost-sensitive applications"]},status:"stable",lastUpdated:"2024-04-16"}),this.registry.register({id:"anthropic.claude-3-haiku-20240307-v1:0",name:"Claude 3 Haiku",provider:u.Anthropic,version:"v1",category:[c.Chat,c.ImageToText,c.Conversation,c.MultilingualSupport],tier:g.Standard,description:"Claude 3 Haiku is Anthropic's fastest, most compact model for near-instant responsiveness.",longDescription:"Claude 3 Haiku is Anthropic's fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with speed. Customers will be able to build seamless AI experiences that mimic human interactions. Claude 3 Haiku can process images and return text outputs, and features a 200K context window.",capabilities:["Fast response time","Image processing","Text generation","Multilingual support"],inputModalities:["text","image"],outputModalities:["text"],maxInputTokens:2e5,streaming:!0,regions:["us-east-1","us-east-2","us-west-2","us-gov-east-1","us-gov-west-1","ap-northeast-1","ap-northeast-2","ap-south-1","ap-southeast-2","ca-central-1","eu-central-1","eu-central-2","eu-west-1","eu-west-2","eu-west-3","sa-east-1"],parameters:this.getCommonTextModelParams(2e5),features:{contextWindow:2e5,multilingual:!0,formatting:!0,imageAnalysis:!0,streamingSupport:!0},useCase:{recommended:["Quick responses","Simple queries","Image analysis","Real-time applications"],notRecommended:["Complex reasoning tasks","Long-form content generation"]},status:"stable",lastUpdated:"2024-03-14"}),this.registry.register({id:"anthropic.claude-v2:1",name:"Claude 2.1",provider:u.Anthropic,version:"2.1",category:[c.TextGeneration,c.Conversation,c.ComplexReasoningAnalysis],tier:g.Premium,description:"An update to Claude 2 that features double the context window, plus improvements across reliability, hallucination rates, and evidence-based accuracy in long document and RAG contexts.",capabilities:[],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:2e5,streaming:!0,regions:["us-east-1","us-west-2","ap-northeast-1","eu-central-1"],parameters:this.getCommonTextModelParams(2e5),features:{contextWindow:2e5,multilingual:!0,formatting:!0},status:"stable",lastUpdated:"2023-11-29"}),this.registry.register({id:"anthropic.claude-v2",name:"Claude 2",provider:u.Anthropic,version:"2",category:[c.TextGeneration,c.Conversation,c.ComplexReasoningAnalysis],tier:g.Premium,description:"Anthropic's highly capable model across a wide range of tasks from sophisticated dialogue and creative content generation to detailed instruction following.",capabilities:[],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:1e5,streaming:!0,regions:["us-east-1","us-west-2","ap-southeast-1","eu-central-1"],parameters:this.getCommonTextModelParams(1e5),features:{contextWindow:1e5,multilingual:!0,formatting:!0},status:"stable",lastUpdated:"2023-08-01"}),this.registry.register({id:"anthropic.claude-instant-v1",name:"Claude Instant",provider:u.Anthropic,version:"1.2",category:[c.TextGeneration,c.Conversation],tier:g.Standard,description:"A fast, affordable yet still very capable model, which can handle a range of tasks including casual dialogue, text analysis, summarization, and document question-answering.",capabilities:[],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:1e5,streaming:!0,regions:["us-east-1","us-west-2","ap-northeast-1","ap-southeast-1","eu-central-1"],parameters:this.getCommonTextModelParams(1e5),features:{contextWindow:1e5,multilingual:!0,formatting:!0},status:"stable",lastUpdated:"2023-08-01"})}}class o extends n{generateModels(){this.registry.register({id:"stability.sd3-large-v1:0",name:"SD3 Large",provider:u.StabilityAI,version:"1.0",category:[c.Image],tier:g.Premium,description:"Stable Diffusion 3 Large (SD3 Large) is our most capable text-to-image model yet, with greatly improved performance in multi-subject prompts, image quality, and spelling abilities.",capabilities:["Multi-subject prompts","Enhanced image quality","Improved spelling abilities","Typography handling","Scene composition"],inputModalities:["text"],outputModalities:["image"],maxInputTokens:77,streaming:!1,regions:[],parameters:this.getCommonImageModelParams(),features:{contextWindow:77,multilingual:!1,formatting:!0,imageGeneration:!0,customTraining:!1},useCase:{recommended:["Text-to-image generation","Anime","Cartoons","Ideation"],notRecommended:[]},status:"stable",lastUpdated:"2024-09-04"}),this.registry.register({id:"stability.stable-image-core-v1:0",name:"Stable Image Core",provider:u.StabilityAI,version:"1.0",category:[c.Image],tier:g.Standard,description:"Create and iterate images quickly and affordably with Stable Image Core, the image service that requires no prompt engineering to get high quality images in diverse styles at high speed.",capabilities:["Fast image generation","No prompt engineering required","Diverse styles"],inputModalities:["text"],outputModalities:["image"],maxInputTokens:77,streaming:!1,regions:[],parameters:this.getCommonImageModelParams(),features:{contextWindow:77,multilingual:!1,formatting:!0,imageGeneration:!0},useCase:{recommended:["Rapid image generation","Simple image creation"],notRecommended:[]},status:"stable",lastUpdated:"2024-09-04"}),this.registry.register({id:"stability.stable-image-ultra-v1:0",name:"Stable Image Ultra",provider:u.StabilityAI,version:"1.0",category:[c.Image],tier:g.Premium,description:"Take your visuals to a whole new level with large, photo realistic output. Enable your organization to go from idea to execution faster, extend your existing resources to achieve more, and empower creative thinking at speed and scale by building on SD3.",capabilities:["Photo realistic output","High-quality visuals","Fast execution","Creative ideation"],inputModalities:["text"],outputModalities:["image"],maxInputTokens:77,streaming:!1,regions:[],parameters:this.getCommonImageModelParams(),features:{contextWindow:77,multilingual:!1,formatting:!0,imageGeneration:!0},useCase:{recommended:["Professional photo-realistic images","High-quality visual content"],notRecommended:[]},status:"stable",lastUpdated:"2024-09-04"})}getCommonImageModelParams(){return{supportsTemperature:!1,supportsTopP:!1,defaultValues:i.IMAGE,limits:{minTokens:1,maxTokens:77}}}}class l extends n{generateModels(){this.registry.register({id:"amazon.titan-embed-text-v1",name:"Titan Embeddings G1 - Text",provider:u.Amazon,version:"1.2",category:[c.Embedding,c.Vector],tier:g.Standard,description:"Titan Embeddings model optimized for text retrieval tasks with multi-language support",longDescription:"The Titan Embeddings G1 – Text can intake up to 8k tokens and outputs a vector of 1536 dimensions. The model works in 25+ different languages and is optimized for text retrieval tasks, semantic similarity, and clustering.",capabilities:["text retrieval","semantic similarity","clustering","document segmentation"],inputModalities:["text"],outputModalities:["embedding"],maxInputTokens:8e3,streaming:!1,regions:["us-east-1","us-west-2","ap-northeast-1","eu-central-1"],parameters:this.getCommonTextModelParams(8e3),features:{contextWindow:8e3,multilingual:!0,vectorDimensions:1536,supportedLanguages:["English","Arabic","Chinese (Sim.)","French","German","Hindi","Japanese","Spanish","Czech","Filipino","Hebrew","Italian","Korean","Portuguese","Russian","Swedish","Turkish","Chinese (trad)","Dutch","Kannada","Malayalam","Marathi","Polish","Tamil","Telugu"]},status:"stable",lastUpdated:"2023-09-28"}),this.registry.register({id:"amazon.titan-text-lite-v1",name:"Titan Text G1 - Lite",provider:u.Amazon,version:"1.0",category:[c.TextGeneration,c.TextSummarization],tier:g.Basic,description:"Lightweight efficient model ideal for fine-tuning English-language tasks",capabilities:["summarization","copywriting","fine-tuning"],inputModalities:["text"],outputModalities:["text"],maxInputTokens:4e3,streaming:!0,regions:["us-east-1","us-west-2","ap-south-1","ap-southeast-2","ca-central-1","eu-central-1","eu-west-1","eu-west-2","eu-west-3","sa-east-1"],parameters:this.getCommonTextModelParams(4e3),features:{contextWindow:4e3,multilingual:!1,finetuning:!0,customTraining:!0},status:"stable",lastUpdated:"2023-11-29"}),this.registry.register({id:"amazon.titan-text-express-v1",name:"Titan Text G1 - Express",provider:u.Amazon,version:"1.0",category:[c.TextGeneration,c.Chat,c.RAG],tier:g.Standard,description:"Model for advanced language tasks with extensive multilingual support",capabilities:["open-ended text generation","conversational chat","RAG support","multilingual processing"],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:8e3,streaming:!0,regions:["us-east-1","us-west-2","us-gov-west-1","ap-northeast-1","ap-south-1","ap-southeast-2","ca-central-1","eu-central-1","eu-west-1","eu-west-2","eu-west-3","sa-east-1"],parameters:this.getCommonTextModelParams(8e3),features:{contextWindow:8e3,multilingual:!0,supportedLanguages:["English","100+ additional languages (Preview)"]},status:"stable",lastUpdated:"2023-11-29"}),this.registry.register({id:"amazon.titan-image-generator-v2:0",name:"Titan Image Generator G1 v2",provider:u.Amazon,version:"2.0",category:[c.Image,c.TextToText,c.ImageToText],tier:g.Standard,description:"Image generation model with text-to-image, image editing, and background removal capabilities",longDescription:"Titan Image Generator is an image generation model. It generates images from text, allows users to upload and edit an existing or generated image. Users can edit an image with a text prompt (without a mask), parts of an image with an image mask, generate variations of an image or remove background automatically.",capabilities:["Text to image generation","Image editing","Background removal","Image conditioning","Subject preservation","Image variations"],inputModalities:["text","image"],outputModalities:["image"],maxInputTokens:512,streaming:!1,regions:["us-east-1","us-west-2"],parameters:this.getCommonImageModelParams(),features:{contextWindow:512,multilingual:!1,formatting:!0,imageGeneration:!0,imageAnalysis:!0},useCase:{recommended:["Image generation","Image editing","Background removal","Image variations"],notRecommended:[]},status:"stable",lastUpdated:"2024-08-06"}),this.registry.register({id:"amazon.titan-image-generator-v1",name:"Titan Image Generator G1",provider:u.Amazon,version:"1.0",category:[c.Image,c.TextToText],tier:g.Standard,description:"First generation image generation model with text-to-image and image editing capabilities",capabilities:["Text to image generation","Image editing","Image masking","Outpainting","Image variations"],inputModalities:["text","image"],outputModalities:["image"],maxInputTokens:512,streaming:!1,regions:["us-east-1","us-west-2","ap-south-1","eu-west-1","eu-west-2"],parameters:this.getCommonImageModelParams(),features:{contextWindow:512,multilingual:!1,formatting:!0,imageGeneration:!0,imageAnalysis:!0},useCase:{recommended:["Image generation","Image editing","Outpainting","Image variations"],notRecommended:[]},status:"stable",lastUpdated:"2023-11-29"}),this.registry.register({id:"amazon.titan-embed-image-v1",name:"Titan Multimodal Embeddings G1",provider:u.Amazon,version:"1.0",category:[c.Embedding,c.Vector,c.Search],tier:g.Standard,description:"Multimodal embeddings model for image and text search use cases",capabilities:["Image search","Text search","Combined text and image search","Recommendations"],inputModalities:["text","image"],outputModalities:["embedding"],maxInputTokens:128,streaming:!1,regions:["us-east-1","us-west-2","ap-south-1","ap-southeast-2","ca-central-1","eu-central-1","eu-west-1","eu-west-2","eu-west-3","sa-east-1"],parameters:this.getCommonEmbeddingModelParams(),features:{contextWindow:128,multilingual:!1,formatting:!0,vectorDimensions:[1024,384,256]},useCase:{recommended:["Image search","Multimodal search","Recommendations"],notRecommended:[]},status:"stable",lastUpdated:"2023-11-29"}),this.registry.register({id:"amazon.titan-embed-text-v2:0",name:"Titan Text Embeddings V2",provider:u.Amazon,version:"2.0",category:[c.Embedding],tier:g.Standard,description:"Light weight, efficient model for high accuracy retrieval tasks at different dimensions",longDescription:"Amazon Titan Text Embeddings V2 is a light weight, efficient model ideal for high accuracy retrieval tasks at different dimensions. The model supports flexible embeddings sizes (1024, 512, and 256) and prioritizes accuracy maintenance at smaller dimension sizes, making it possible to reduce storage costs without compromising on accuracy.",capabilities:["Multiple embedding dimensions (1024, 512, 256)","Multi-lingual support for 100+ languages","Unit vector normalization"],inputModalities:["text"],outputModalities:["embedding"],maxInputTokens:8e3,streaming:!1,regions:["us-east-1","us-east-2","us-west-2","us-gov-west-1","ap-northeast-2","ap-southeast-2","ca-central-1","eu-central-1","eu-central-2","eu-west-2","sa-east-1"],parameters:this.getCommonEmbeddingModelParams(),features:{contextWindow:8e3,multilingual:!0,formatting:!0},useCase:{recommended:["Embedding generation","Retrieval tasks","Vector search"],notRecommended:[]},status:"stable",lastUpdated:"2024-04-30"}),this.registry.register({id:"amazon.rerank-v1:0",name:"Rerank",provider:u.Amazon,version:"1.0",category:[c.Search],tier:g.Standard,description:"Orders documents based on their relevance to user queries",longDescription:"Amazon's Rerank model orders a set of documents based on their relevance to a user's query. This ordering helps you prioritize the most relevant content to be passed to a foundation model for response generation, which in turn boosts the relevance and accuracy of the generated responses.",capabilities:["Document reranking","Relevance scoring","Multi-lingual support"],maxInputTokens:1e4,inputModalities:["text"],outputModalities:["text"],streaming:!1,regions:["us-east-1"],parameters:this.getCommonTextModelParams(1e4),features:{contextWindow:2e4,multilingual:!0,formatting:!0},useCase:{recommended:["Document ranking","Search optimization","Content prioritization"],notRecommended:[]},status:"stable",lastUpdated:"2024-12-01"}),this.registry.register({id:"amazon.nova-pro-v1:0",name:"Nova Pro",provider:u.Amazon,version:"1.0",category:[c.Multimodal],tier:g.Premium,description:"Multimodal understanding foundation model",longDescription:"Nova Pro is a multimodal understanding foundation model. It is multilingual and can reason over text, images and videos.",capabilities:["Text understanding","Image analysis","Video analysis","Multi-lingual support"],inputModalities:["text","image","video"],outputModalities:["text"],maxInputTokens:3e5,streaming:!0,regions:["us-east-1"],parameters:this.getCommonTextModelParams(3e5),features:{contextWindow:3e5,multilingual:!0,formatting:!0,imageAnalysis:!0,multimodal:!0},useCase:{recommended:["Multimodal analysis","Content understanding","Cross-modal reasoning"],notRecommended:[]},status:"stable",lastUpdated:"2024-12-03"}),this.registry.register({id:"amazon.nova-lite-v1:0",name:"Nova Lite",provider:u.Amazon,version:"1.0",category:[c.Multimodal,c.TextToText,c.ImageToText],tier:g.Standard,description:"Nova Lite is a multimodal understanding foundation model. It is multilingual and can reason over text, images and videos.",capabilities:["text understanding","image understanding","video understanding","multilingual support"],inputModalities:["text","image","video"],outputModalities:["text"],maxInputTokens:3e5,streaming:!0,regions:["us-east-1"],parameters:this.getCommonTextModelParams(3e5),features:{contextWindow:3e5,multilingual:!0,formatting:!0,multimodal:!0,imageAnalysis:!0,streamingSupport:!0,supportedLanguages:["200+"]},useCase:{recommended:["Multimodal analysis","Multilingual tasks","Text generation"],notRecommended:[]},status:"stable",lastUpdated:"2024-12-03"}),this.registry.register({id:"amazon.nova-micro-v1:0",name:"Nova Micro",provider:u.Amazon,version:"1.0",category:[c.TextToText,c.NaturalLanguageProcessing],tier:g.Basic,description:"Nova Micro is a text - text understanding foundation model. It is multilingual and can reason over text.",capabilities:["text understanding","multilingual support"],inputModalities:["text"],outputModalities:["text"],maxInputTokens:128e3,streaming:!0,regions:["us-east-1"],parameters:this.getCommonTextModelParams(128e3),features:{contextWindow:128e3,multilingual:!0,formatting:!0,streamingSupport:!0,supportedLanguages:["200+"]},useCase:{recommended:["Text analysis","Multilingual tasks"],notRecommended:["Multimodal tasks"]},status:"stable",lastUpdated:"2024-12-03"})}getCommonEmbeddingModelParams(){return{supportsTemperature:!1,supportsTopP:!1,defaultValues:{},limits:{}}}}class d extends n{generateModels(){this.registry.register({id:"us.meta.llama3-2-1b-instruct-v1:0",name:"Llama 3.2 1B Instruct",provider:u.Meta,version:"v1",category:[c.Agents,c.CodeGeneration,c.ComplexReasoningAnalysis,c.Conversation,c.TextSummarization,c.Math,c.MultilingualSupport,c.NaturalLanguageProcessing,c.QuestionAnswering,c.RAG,c.TextGeneration,c.TextToText,c.Translation],tier:g.Standard,description:"Text-only model, supporting on-device use cases such as multilingual local knowledge retrieval, summarization, and rewriting.",longDescription:"The Llama 3.2 1B Instruct model is a lightweight, fine-tuned model that delivers efficient and private capabilities, leveraging 1 billion parameters and text-only functionality to provide fast and accurate results.",capabilities:["Multilingual dialogue","Personal information management","Knowledge retrieval","Text rewriting"],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:131e3,streaming:!0,regions:["us-east-1","us-east-2","us-west-2","eu-central-1","eu-west-1","eu-west-3"],parameters:this.getCommonTextModelParams(131e3),features:{contextWindow:131e3,multilingual:!0,formatting:!0,supportedLanguages:["English","German","French","Italian","Portuguese","Hindi","Spanish","Thai"]},useCase:{recommended:["On-device processing","Edge device applications","Multilingual tasks"],notRecommended:["Complex reasoning tasks requiring larger models"]},status:"stable",lastUpdated:"2024-09-25"}),this.registry.register({id:"us.meta.llama3-2-3b-instruct-v1:0",name:"Llama 3.2 3B Instruct",provider:u.Meta,version:"v1",category:[c.Agents,c.CodeGeneration,c.ComplexReasoningAnalysis,c.Conversation,c.TextSummarization,c.Math,c.MultilingualSupport,c.NaturalLanguageProcessing,c.QuestionAnswering,c.RAG,c.TextGeneration,c.TextToText,c.Translation],tier:g.Standard,description:"Text-only model, fine-tuned for supporting on-device use cases such as multilingual local knowledge retrieval, summarization, and rewriting.",longDescription:"The Llama 3.2 3B Instruct model is a lightweight, fine-tuned model, leveraging 3 billion parameters to deliver highly accurate and relevant results.",capabilities:["Advanced text generation","Summarization","Sentiment analysis","Emotional intelligence","Contextual understanding"],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:131e3,streaming:!0,regions:["us-east-1","us-east-2","us-west-2","eu-central-1","eu-west-1","eu-west-3"],parameters:this.getCommonTextModelParams(131e3),features:{contextWindow:131e3,multilingual:!0,formatting:!0,supportedLanguages:["English","German","French","Italian","Portuguese","Hindi","Spanish","Thai"]},useCase:{recommended:["Mobile AI writing assistants","Customer service applications","Edge device applications"],notRecommended:["Tasks requiring visual understanding"]},status:"stable",lastUpdated:"2024-09-25"}),this.registry.register({id:"us.meta.llama3-2-11b-instruct-v1:0",name:"Llama 3.2 11B Vision Instruct",provider:u.Meta,version:"v1",category:[c.ComplexReasoningAnalysis,c.Conversation,c.ImageToText,c.Math,c.MultilingualSupport,c.NaturalLanguageProcessing,c.QuestionAnswering,c.RAG,c.TextGeneration,c.TextToText,c.Translation],tier:g.Premium,description:"Instruction-tuned image reasoning generative model (text + images in / text out) optimized for visual recognition, image reasoning, captioning and answering general questions about the image.",longDescription:"The Llama 3.2 11B Vision Instruct model is a multimodal, fine-tuned model, leveraging 11 billion parameters to deliver unparalleled capabilities in image understanding, visual reasoning, and multimodal interaction.",capabilities:["Image captioning","Image-text retrieval","Visual grounding","Visual question answering","Document visual question answering"],inputModalities:["text","image"],outputModalities:["text","chat"],maxInputTokens:128e3,streaming:!0,regions:["us-east-1","us-east-2","us-west-2"],parameters:this.getCommonTextModelParams(128e3),features:{contextWindow:128e3,multilingual:!0,formatting:!0,imageAnalysis:!0,multimodal:!0,supportedLanguages:["English","German","French","Italian","Portuguese","Hindi","Spanish","Thai"]},useCase:{recommended:["Image analysis","Document processing","Multimodal chatbots"],notRecommended:["Text-only applications"]},status:"stable",lastUpdated:"2024-09-25"}),this.registry.register({id:"us.meta.llama3-2-90b-instruct-v1:0",name:"Llama 3.2 90B Vision Instruct",provider:u.Meta,version:"v1",category:[c.Chat,c.CodeGeneration,c.ComplexReasoningAnalysis,c.Conversation,c.ImageToText,c.Math,c.MultilingualSupport,c.NaturalLanguageProcessing,c.QuestionAnswering,c.RAG,c.TextGeneration,c.TextSummarization,c.Translation],tier:g.Premium,description:"Instruction-tuned image reasoning generative model optimized for visual recognition, image reasoning, captioning and answering general questions about the image",longDescription:"The Llama 3.2 90B Vision Instruct model is a multimodal, fine-tuned model, leveraging 90 billion parameters to deliver unparalleled capabilities in image understanding, visual reasoning, and multimodal interaction...",capabilities:["Image captioning","Visual reasoning","Visual question answering","Document visual question answering","Multimodal interaction"],inputModalities:["text","image"],outputModalities:["text","chat"],maxInputTokens:128e3,maxOutputTokens:128e3,streaming:!0,regions:["us-east-1","us-east-2","us-west-2"],parameters:this.getCommonTextModelParams(128e3),features:{contextWindow:128e3,multilingual:!0,formatting:!0,imageAnalysis:!0,multimodal:!0,supportedLanguages:["English","German","French","Italian","Portuguese","Hindi","Spanish","Thai"]},useCase:{recommended:["Image analysis","Document processing","Multimodal chatbots","Autonomous systems"],notRecommended:[]},status:"stable",lastUpdated:"2024-09-25"}),this.registry.register({id:"meta.llama3-1-405b-instruct-v1:0",name:"Llama 3.1 405B Instruct",provider:u.Meta,version:"v1",category:[c.Chat,c.ComplexReasoningAnalysis,c.Conversation,c.MultilingualSupport,c.TextGeneration],tier:g.Premium,description:"Meta Llama 3.1 405B Instruct is the largest and most powerful of the Llama 3.1 Instruct models",longDescription:"Meta Llama 3.1 405B Instruct is the largest and most powerful of the Llama 3.1 Instruct models that is a highly advanced model for conversational inference and reasoning, synthetic data generation...",capabilities:["Conversational inference","Reasoning","Synthetic data generation","Specialized domain adaptation"],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:128e3,maxOutputTokens:128e3,streaming:!0,regions:["us-west-2"],parameters:this.getCommonTextModelParams(128e3),features:{contextWindow:128e3,multilingual:!0,formatting:!0,supportedLanguages:["English","German","French","Italian","Portuguese","Hindi","Spanish","Thai"]},useCase:{recommended:["Assistant-like chat","Natural language generation","Synthetic data generation","Model distillation"],notRecommended:[]},status:"stable",lastUpdated:"2024-07-23"}),this.registry.register({id:"meta.llama3-1-70b-instruct-v1:0",name:"Llama 3.1 70B Instruct",provider:u.Meta,version:"v1",category:[c.Chat,c.TextGeneration,c.MultilingualSupport,c.ComplexReasoningAnalysis],tier:g.Premium,description:"An update to Meta Llama 3 70B Instruct that includes an expanded 128K context length, multilinguality and improved reasoning capabilities.",longDescription:"The Llama 3.1 offering of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models. The models are optimized for multilingual dialogue use cases and outperform many of the available open source chat models on common industry benchmarks.",capabilities:["Multilingual dialogue","Instruction following","Improved reasoning","Assistant-like chat","Synthetic data generation"],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:128e3,streaming:!0,regions:["us-east-1","us-east-2","us-west-2","us-gov-west-1"],parameters:this.getCommonTextModelParams(128e3),features:{contextWindow:128e3,multilingual:!0,formatting:!0,streamingSupport:!0,supportedLanguages:["English","German","French","Italian","Portuguese","Hindi","Spanish","Thai"]},useCase:{recommended:["Multilingual applications","Assistant-like chat","Complex reasoning tasks","Natural language generation"],notRecommended:[]},status:"stable",lastUpdated:"2024-07-23"}),this.registry.register({id:"meta.llama3-1-8b-instruct-v1:0",name:"Llama 3.1 8B Instruct",provider:u.Meta,version:"1.0",category:[c.TextToText,c.Chat,c.MultilingualSupport,c.ComplexReasoningAnalysis],tier:g.Standard,description:"An update to Meta Llama 3 8B Instruct that includes an expanded 128K context length, multilinguality and improved reasoning capabilities.",capabilities:["Multilingual dialogue","Improved reasoning","Assistant-like chat","Natural language generation"],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:128e3,streaming:!0,regions:["us-east-1","us-east-2","us-west-2","us-gov-west-1"],parameters:this.getCommonTextModelParams(128e3),features:{contextWindow:128e3,multilingual:!0,formatting:!0,streamingSupport:!0,supportedLanguages:["English","German","French","Italian","Portuguese","Hindi","Spanish","Thai"]},useCase:{recommended:["Multilingual applications","Dialogue systems","Assistant-like chat"],notRecommended:[]},status:"stable",lastUpdated:"2024-07-23"}),this.registry.register({id:"meta.llama3-8b-instruct-v1:0",name:"Llama 3 8B Instruct",provider:u.Meta,version:"1.0",category:[c.TextSummarization,c.NaturalLanguageProcessing],tier:g.Standard,description:"Ideal for limited computational power and resources, edge devices, and faster training times.",capabilities:["Text summarization","Text classification","Sentiment analysis"],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:8e3,streaming:!0,regions:["us-east-1","us-west-2","ap-south-1","ca-central-1","eu-west-2"],parameters:this.getCommonTextModelParams(8e3),features:{contextWindow:8e3,multilingual:!1,formatting:!0,streamingSupport:!0,supportedLanguages:["English"]},useCase:{recommended:["Edge devices","Limited computational resources","Fast training"],notRecommended:[]},status:"stable",lastUpdated:"2024-04-18"}),this.registry.register({id:"meta.llama3-70b-instruct-v1:0",name:"Llama 3 70B Instruct",provider:u.Meta,version:"1.0",category:[c.TextGeneration,c.Chat,c.CodeGeneration],tier:g.Premium,description:"Ideal for content creation, conversational AI, language understanding, R&D, and Enterprise applications.",capabilities:["Language modeling","Dialog systems","Code generation","Text classification","Text summarization","Sentiment analysis"],inputModalities:["text"],outputModalities:["text","chat"],maxInputTokens:8e3,streaming:!0,regions:["us-east-1","us-west-2","ap-south-1","ca-central-1","eu-west-2"],parameters:this.getCommonTextModelParams(8e3),features:{contextWindow:8e3,multilingual:!1,formatting:!0,streamingSupport:!0,supportedLanguages:["English"]},useCase:{recommended:["Content creation","Conversational AI","Enterprise applications","R&D"],notRecommended:[]},status:"stable",lastUpdated:"2024-04-18"})}}let m=null;var u=function(e){return e.Anthropic="Anthropic",e.Amazon="Amazon",e.Meta="Meta",e.MistralAI="Mistral AI",e.Cohere="Cohere",e.AI21Labs="AI21 Labs",e.StabilityAI="Stability AI",e.Google="Google",e.OpenAI="OpenAI",e}({}),c=function(e){return e.All="all",e.Text="text",e.Chat="chat",e.Image="image",e.Embedding="embedding",e.Multimodal="multimodal",e.Vector="vector",e.Search="search",e.Audio="audio",e.Video="video",e.Agents="agents",e.CodeGeneration="code generation",e.ComplexReasoningAnalysis="complex reasoning analysis",e.Conversation="conversation",e.ImageToText="image-to-text",e.Math="math",e.MultilingualSupport="multilingual support",e.NaturalLanguageProcessing="natural language processing",e.QuestionAnswering="question answering",e.RAG="rag",e.TextGeneration="text generation",e.TextSummarization="text summarization",e.TextToText="text-to-text",e.Translation="translation",e}({}),g=function(e){return e.Free="free",e.Basic="basic",e.Standard="standard",e.Premium="premium",e.Enterprise="enterprise",e}({});let p=function(){if(m)return m;let e=s.getInstance();return[new r,new o,new l,new d].forEach(e=>e.generateModels()),m=e.getModels()}();(e=>{let t=e.filter(e=>e.provider===u.Anthropic),a=[{name:"Claude 3",description:"Latest generation of Claude models with multimodal capabilities",models:t.filter(e=>e.name.toLowerCase().includes("claude-3")),category:c.Multimodal,provider:u.Anthropic,tags:["multimodal","latest","high-performance"],metadata:{series:"claude-3",capabilities:["text","image","analysis"]}},{name:"Claude 2",description:"Production-ready models for general-purpose use",models:t.filter(e=>e.name.toLowerCase().includes("claude-2")),category:c.TextGeneration,provider:u.Anthropic,tags:["stable","general-purpose"],metadata:{series:"claude-2",capabilities:["text","analysis"]}},{name:"Claude Instant",description:"Fast and cost-effective models for simpler tasks",models:t.filter(e=>e.name.toLowerCase().includes("instant")),category:c.TextGeneration,provider:u.Anthropic,tags:["fast","efficient"],metadata:{series:"claude-instant",capabilities:["text"]}}],s=[{name:"Multimodal Models",description:"Models that can process both text and images",models:t.filter(e=>e.inputModalities.includes("image")),category:c.Multimodal,provider:u.Anthropic,tags:["multimodal","vision"]},{name:"Text Models",description:"Models specialized in text processing and generation",models:t.filter(e=>!e.inputModalities.includes("image")),category:c.TextGeneration,provider:u.Anthropic,tags:["text","chat"]}],i=[{name:"High-Performance",description:"Most capable models for complex tasks",models:t.filter(e=>e.name.toLowerCase().includes("opus")||e.name.toLowerCase().includes("claude-3")),category:c.ComplexReasoningAnalysis,provider:u.Anthropic,tags:["high-performance","complex-tasks"]},{name:"Balanced Performance",description:"Good balance of capability and efficiency",models:t.filter(e=>e.name.toLowerCase().includes("claude-2")||e.name.toLowerCase().includes("sonnet")),category:c.TextGeneration,provider:u.Anthropic,tags:["balanced","general-purpose"]},{name:"Efficient Performance",description:"Fast and cost-effective models",models:t.filter(e=>e.name.toLowerCase().includes("instant")||e.name.toLowerCase().includes("haiku")),category:c.TextGeneration,provider:u.Anthropic,tags:["efficient","fast"]}],n=e=>e.filter(e=>e.models.length>0);return[...n(a),...n(s),...n(i)].forEach(e=>{e.metadata={...e.metadata,maxTokens:Math.max(...e.models.map(e=>e.maxInputTokens||0)),multilingualSupport:e.models.every(e=>{var t;return null===(t=e.features)||void 0===t?void 0:t.multilingual}),streamingSupport:e.models.every(e=>e.streaming)}})})(p)},5034:(e,t,a)=>{a.d(t,{Z:()=>i});class s{async initDB(){return new Promise((e,t)=>{let a=indexedDB.open(this.dbName,this.version);a.onerror=()=>t(a.error),a.onsuccess=()=>e(a.result),a.onupgradeneeded=e=>{let t=e.target.result;if(t.objectStoreNames.contains(this.storeName)||t.createObjectStore(this.storeName),t.objectStoreNames.contains(this.modelStore)||t.createObjectStore(this.modelStore),t.objectStoreNames.contains(this.formStateStore)||t.createObjectStore(this.formStateStore),t.objectStoreNames.contains(this.availableModelsStore)||t.createObjectStore(this.availableModelsStore),t.objectStoreNames.contains(this.settingsStore)||t.createObjectStore(this.settingsStore),!t.objectStoreNames.contains(this.conversationsStore)){let e=t.createObjectStore(this.conversationsStore,{keyPath:"id"});e.createIndex("title","title",{unique:!1}),e.createIndex("createdAt","createdAt",{unique:!1}),e.createIndex("lastEditedAt","lastEditedAt",{unique:!1})}if(!t.objectStoreNames.contains(this.agentsStore)){let e=t.createObjectStore(this.agentsStore,{keyPath:"id"});e.createIndex("name","name",{unique:!1}),e.createIndex("updatedAt","updatedAt",{unique:!1})}}})}async saveCredentials(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.storeName,"readwrite").objectStore(this.storeName).put(e,"awsCredentials");i.onerror=()=>s(i.error),i.onsuccess=()=>a()})}async getCredentials(){let e=await this.initDB();return new Promise((t,a)=>{let s=e.transaction(this.storeName,"readonly").objectStore(this.storeName).get("awsCredentials");s.onerror=()=>a(s.error),s.onsuccess=()=>t(s.result||null)})}async deleteCredentials(){let e=await this.initDB();return new Promise((t,a)=>{let s=e.transaction(this.storeName,"readwrite").objectStore(this.storeName).delete("awsCredentials");s.onerror=()=>a(s.error),s.onsuccess=()=>t()})}async saveModelPreference(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.modelStore,"readwrite").objectStore(this.modelStore).put(e,"currentModel");i.onerror=()=>s(i.error),i.onsuccess=()=>a()})}async getModelPreference(){let e=await this.initDB();return new Promise((t,a)=>{let s=e.transaction(this.modelStore,"readonly").objectStore(this.modelStore).get("currentModel");s.onerror=()=>a(s.error),s.onsuccess=()=>t(s.result||null)})}async saveFormState(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.formStateStore,"readwrite").objectStore(this.formStateStore).put(e,"currentFormState");i.onerror=()=>s(i.error),i.onsuccess=()=>a()})}async getFormState(){let e=await this.initDB();return new Promise((t,a)=>{let s=e.transaction(this.formStateStore,"readonly").objectStore(this.formStateStore).get("currentFormState");s.onerror=()=>a(s.error),s.onsuccess=()=>t(s.result||null)})}async saveAvailableModels(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.availableModelsStore,"readwrite").objectStore(this.availableModelsStore).put(e,e.region);i.onerror=()=>s(i.error),i.onsuccess=()=>a()})}async getAvailableModels(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.availableModelsStore,"readonly").objectStore(this.availableModelsStore).get(e);i.onerror=()=>s(i.error),i.onsuccess=()=>a(i.result||null)})}async saveConversation(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.conversationsStore,"readwrite").objectStore(this.conversationsStore).put(e);i.onerror=()=>s(i.error),i.onsuccess=()=>a()})}async getConversation(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.conversationsStore,"readonly").objectStore(this.conversationsStore).get(e);i.onerror=()=>s(i.error),i.onsuccess=()=>a(i.result||null)})}async updateConversation(e,t){let a=await this.getConversation(e);if(!a)throw Error("Conversation not found");let s={...a,...t,lastEditedAt:Date.now()};await this.saveConversation(s)}async saveSettings(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.settingsStore,"readwrite").objectStore(this.settingsStore).put(e,"appSettings");i.onerror=()=>s(i.error),i.onsuccess=()=>a()})}async getSettings(){let e=await this.initDB();return new Promise((t,a)=>{let s=e.transaction(this.settingsStore,"readonly").objectStore(this.settingsStore).get("appSettings");s.onerror=()=>a(s.error),s.onsuccess=()=>t(s.result||null)})}async saveAgent(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.agentsStore,"readwrite").objectStore(this.agentsStore).put(e);i.onerror=()=>s(i.error),i.onsuccess=()=>a()})}async getAgent(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.agentsStore,"readonly").objectStore(this.agentsStore).get(e);i.onerror=()=>s(i.error),i.onsuccess=()=>a(i.result||null)})}async getAllAgents(){let e=await this.initDB();return new Promise((t,a)=>{let s=e.transaction(this.agentsStore,"readonly").objectStore(this.agentsStore).getAll();s.onerror=()=>a(s.error),s.onsuccess=()=>t(s.result||[])})}async deleteAgent(e){let t=await this.initDB();return new Promise((a,s)=>{let i=t.transaction(this.agentsStore,"readwrite").objectStore(this.agentsStore).delete(e);i.onerror=()=>s(i.error),i.onsuccess=()=>a()})}constructor(){this.dbName="ChatAppDB",this.storeName="credentials",this.modelStore="modelPreferences",this.formStateStore="formState",this.availableModelsStore="availableModels",this.conversationsStore="conversations",this.settingsStore="settings",this.agentsStore="agents",this.version=7}}let i=new s},14778:(e,t,a)=>{a.d(t,{UT:()=>i});var s=a(69635);let i=e=>{let t=s.L6.find(t=>t.id===e);if(t)return t}}}]);